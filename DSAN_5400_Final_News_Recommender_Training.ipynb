{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/jaredzrks0/DSAN5400_final_project/blob/main/DSAN_5400_Final_News_Recommender_Training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ilhaXrcxiNFY"
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3ecAxG4-Wifu",
    "outputId": "5fda613b-618a-4a8c-f8a8-efcabe89f627"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: cannot change to 'ColBERT/': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "# Install ColBERT and add to path\n",
    "\n",
    "!git -C ColBERT/ pull || git clone https://github.com/stanford-futuredata/ColBERT.git > /dev/null 2>&1\n",
    "import sys; sys.path.insert(0, 'ColBERT/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4ymdWYpPpdVH",
    "outputId": "b782d267-af1b-48de-81af-391a78f95226"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-12-06 21:51:27--  https://downloads.cs.stanford.edu/nlp/data/colbert/colbertv2/colbertv2.0.tar.gz\n",
      "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
      "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 405924985 (387M) [application/octet-stream]\n",
      "Saving to: ‘colbertv2.0.tar.gz’\n",
      "\n",
      "colbertv2.0.tar.gz  100%[===================>] 387.12M  5.02MB/s    in 72s     \n",
      "\n",
      "2024-12-06 21:52:39 (5.41 MB/s) - ‘colbertv2.0.tar.gz’ saved [405924985/405924985]\n",
      "\n",
      "colbertv2.0/\n",
      "colbertv2.0/artifact.metadata\n",
      "colbertv2.0/vocab.txt\n",
      "colbertv2.0/tokenizer.json\n",
      "colbertv2.0/special_tokens_map.json\n",
      "colbertv2.0/tokenizer_config.json\n",
      "colbertv2.0/config.json\n",
      "colbertv2.0/pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "# Download the ColBERT Checkpoint\n",
    "!wget \"https://downloads.cs.stanford.edu/nlp/data/colbert/colbertv2/colbertv2.0.tar.gz\"\n",
    "!mkdir -p checkpoints  # Create the 'checkpoints' directory if it doesn't exist\n",
    "!tar -xvzf colbertv2.0.tar.gz -C checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "98vo3zu0aLF2"
   },
   "outputs": [],
   "source": [
    "try: # When on google Colab, let's install all dependencies with pip.\n",
    "    import google.colab\n",
    "    !pip install -U pip > /dev/null 2>&1\n",
    "    !pip install fsspec==2024.9.0 > /dev/null 2>&1\n",
    "    !pip install -e ColBERT/['faiss-gpu','torch'] > /dev/null 2>&1\n",
    "    !pip install --upgrade torch torchvision torchaudio > /dev/null 2>&1\n",
    "except Exception:\n",
    "  import sys; sys.path.insert(0, 'ColBERT/')\n",
    "  try:\n",
    "    from colbert import Indexer, Searcher\n",
    "  except Exception:\n",
    "    print(\"If you're running outside Colab, please make sure you install ColBERT in conda following the instructions in our README. You can also install (as above) with pip but it may install slower or less stable faiss or torch dependencies. Conda is recommended.\")\n",
    "    assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "jbR_4yFoaTPY"
   },
   "outputs": [],
   "source": [
    "# ColBERT Imports\n",
    "import colbert\n",
    "from colbert import Indexer, Searcher\n",
    "from colbert.infra import Run, RunConfig, ColBERTConfig\n",
    "from colbert.data import Queries, Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "g5Eq9bCRic5C"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "source\n",
       "CNN                   2952\n",
       "Fox News              2162\n",
       "Al Jazeera English    1571\n",
       "AP News               1042\n",
       "Washington Post        584\n",
       "BBC News               514\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('src/article_scraping/data/corpus_info.csv')\n",
    "df.source.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "e1NedVeDji0V"
   },
   "outputs": [],
   "source": [
    "# Clean the df to get just a list of strings\n",
    "texts = df[0]\n",
    "articles = [text.split('\\t')[1] for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "o1dSunw-bbfo"
   },
   "outputs": [],
   "source": [
    "nbits = 2   # encode each dimension with 2 bits\n",
    "doc_maxlen = 300 # truncate passages at 300 tokens\n",
    "\n",
    "index_name = f'dsan5400_project_nbits={nbits}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 290,
     "referenced_widgets": [
      "0234cde8d0c54b8fa9c0ebfa5b2fc702",
      "919d4b2e086244d8973c84d199ade9b2",
      "20443808c5b8474396d77d8d7104b0e1",
      "c3605087ec8848ab9fde572f4cd632fb",
      "067539e89bdf42a998eecea25262e9e9",
      "1e10cbae18fd4762936a7222793e55a1",
      "5e80b44a008646659789ca69baac6f74",
      "819301415e8d4b308f5665458439996f",
      "8aa71113a3f0467792f9771cb5d71550",
      "58a308a13bbb4effb17c89b095427097",
      "f6ce0df847004b42b65ca7b0461e62a1"
     ]
    },
    "id": "R2iGv89OuX-d",
    "outputId": "b242f809-e30f-4fe8-f9a3-1611ffbcf908"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0234cde8d0c54b8fa9c0ebfa5b2fc702",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "artifact.metadata:   0%|          | 0.00/1.63k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "[Dec 06, 22:02:33] #> Creating directory /content/experiments/DSAN5400/indexes/dsan5400_project_nbits=2 \n",
      "\n",
      "\n",
      "#> Starting...\n",
      "#> Joined...\n"
     ]
    }
   ],
   "source": [
    "checkpoint = 'colbert-ir/colbertv2.0'\n",
    "\n",
    "with Run().context(RunConfig(nranks=1, experiment='DSAN5400')):  # nranks specifies the number of GPUs to use\n",
    "    config = ColBERTConfig(doc_maxlen=doc_maxlen, nbits=nbits, kmeans_niters=4) # kmeans_niters specifies the number of iterations of k-means clustering; 4 is a good and fast default.\n",
    "                                                                                # Consider larger numbers for small datasets.\n",
    "\n",
    "    indexer = Indexer(checkpoint=checkpoint, config=config)\n",
    "    indexer.index(name=index_name, collection=articles[:500], overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Kh4iXEjT0Crx",
    "outputId": "ccbe33b4-9c47-42d9-b202-91afa0ca7cbd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Dec 06, 22:11:27] #> Loading codec...\n",
      "[Dec 06, 22:11:27] Loading decompress_residuals_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/content/ColBERT/colbert/utils/amp.py:12: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler()\n",
      "/content/ColBERT/colbert/indexing/codecs/residual.py:141: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  centroids = torch.load(centroids_path, map_location='cpu')\n",
      "/content/ColBERT/colbert/indexing/codecs/residual.py:142: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  avg_residual = torch.load(avgresidual_path, map_location='cpu')\n",
      "/content/ColBERT/colbert/indexing/codecs/residual.py:143: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  bucket_cutoffs, bucket_weights = torch.load(buckets_path, map_location='cpu')\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/cpp_extension.py:1964: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n",
      "If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Dec 06, 22:11:27] Loading packbits_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/utils/cpp_extension.py:1964: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n",
      "If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Dec 06, 22:11:27] #> Loading IVF...\n",
      "[Dec 06, 22:11:27] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/content/ColBERT/colbert/search/index_loader.py:33: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ivf, ivf_lengths = torch.load(os.path.join(self.index_path, \"ivf.pid.pt\"), map_location='cpu')\n",
      "100%|██████████| 1/1 [00:00<00:00, 4733.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Dec 06, 22:11:27] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]/content/ColBERT/colbert/indexing/codecs/residual_embeddings.py:86: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(codes_path, map_location='cpu')\n",
      "/content/ColBERT/colbert/indexing/codecs/residual_embeddings.py:93: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(residuals_path, map_location='cpu')\n",
      "100%|██████████| 1/1 [00:00<00:00, 80.92it/s]\n"
     ]
    }
   ],
   "source": [
    "# To create the searcher using its relative name (i.e., not a full path), set\n",
    "# experiment=value_used_for_indexing in the RunConfig.\n",
    "with Run().context(RunConfig(experiment='DSAN5400')):\n",
    "    searcher = Searcher(index=index_name, collection=articles[:500])\n",
    "\n",
    "\n",
    "# If you want to customize the search latency--quality tradeoff, you can also supply a\n",
    "# config=ColBERTConfig(ncells=.., centroid_score_threshold=.., ndocs=..) argument.\n",
    "# The default settings with k <= 10 (1, 0.5, 256) gives the fastest search,\n",
    "# but you can gain more extensive search by setting larger values of k or\n",
    "# manually specifying more conservative ColBERTConfig settings (e.g. (4, 0.4, 4096))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6e43e5d3137b45c98efc2fb0987d7918": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_91d86eadf2624b95b4e362af21b0ec78",
              "IPY_MODEL_65728deeee174f5798350f6b0a1b554d",
              "IPY_MODEL_f1e6c21d9a7e439abc9d85298ca267f6"
            ],
            "layout": "IPY_MODEL_508f7f99db2441df81f6c1ba6388fd06"
          }
        },
        "91d86eadf2624b95b4e362af21b0ec78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d103f199acef4207bb09b78538ad39b1",
            "placeholder": "​",
            "style": "IPY_MODEL_253fa04f2f0843dd9a37d09ca36a0980",
            "value": "artifact.metadata: 100%"
          }
        },
        "65728deeee174f5798350f6b0a1b554d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5b0c0233f67a4b0497ff84390cb40d6e",
            "max": 1633,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e51aaec57a514792bda0fc794b172051",
            "value": 1633
          }
        },
        "f1e6c21d9a7e439abc9d85298ca267f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2b60d3cb563c44e1a3bd6709fbbe7d76",
            "placeholder": "​",
            "style": "IPY_MODEL_c3b24ae7bcdd4c8694223a8682128f49",
            "value": " 1.63k/1.63k [00:00&lt;00:00, 55.8kB/s]"
          }
        },
        "508f7f99db2441df81f6c1ba6388fd06": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d103f199acef4207bb09b78538ad39b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "253fa04f2f0843dd9a37d09ca36a0980": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5b0c0233f67a4b0497ff84390cb40d6e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e51aaec57a514792bda0fc794b172051": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2b60d3cb563c44e1a3bd6709fbbe7d76": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3b24ae7bcdd4c8694223a8682128f49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jaredzrks0/DSAN5400_final_project/blob/main/DSAN_5400_Final_News_Recommender_Training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os"
      ],
      "metadata": {
        "id": "ilhaXrcxiNFY"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "3ecAxG4-Wifu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "877056be-dade-40cf-a5ce-01c4f6efd064"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: cannot change to 'ColBERT/': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "# Install ColBERT and add to path\n",
        "\n",
        "!git -C ColBERT/ pull || git clone https://github.com/stanford-futuredata/ColBERT.git > /dev/null 2>&1\n",
        "import sys; sys.path.insert(0, 'ColBERT/')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the ColBERT Checkpoint\n",
        "!wget \"https://downloads.cs.stanford.edu/nlp/data/colbert/colbertv2/colbertv2.0.tar.gz\"\n",
        "!mkdir -p checkpoints  # Create the 'checkpoints' directory if it doesn't exist\n",
        "!tar -xvzf colbertv2.0.tar.gz -C checkpoints"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ymdWYpPpdVH",
        "outputId": "b7353372-9b56-440e-c5ca-f4f0ef64bbb8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-12-09 23:49:09--  https://downloads.cs.stanford.edu/nlp/data/colbert/colbertv2/colbertv2.0.tar.gz\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 405924985 (387M) [application/octet-stream]\n",
            "Saving to: ‘colbertv2.0.tar.gz’\n",
            "\n",
            "colbertv2.0.tar.gz  100%[===================>] 387.12M  5.10MB/s    in 75s     \n",
            "\n",
            "2024-12-09 23:50:24 (5.19 MB/s) - ‘colbertv2.0.tar.gz’ saved [405924985/405924985]\n",
            "\n",
            "colbertv2.0/\n",
            "colbertv2.0/artifact.metadata\n",
            "colbertv2.0/vocab.txt\n",
            "colbertv2.0/tokenizer.json\n",
            "colbertv2.0/special_tokens_map.json\n",
            "colbertv2.0/tokenizer_config.json\n",
            "colbertv2.0/config.json\n",
            "colbertv2.0/pytorch_model.bin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try: # When on google Colab, let's install all dependencies with pip.\n",
        "    import google.colab\n",
        "    !pip install -U pip > /dev/null 2>&1\n",
        "    !pip install fsspec==2024.9.0 > /dev/null 2>&1\n",
        "    !pip install -e ColBERT/['faiss-gpu','torch'] > /dev/null 2>&1\n",
        "    !pip install --upgrade torch torchvision torchaudio > /dev/null 2>&1\n",
        "except Exception:\n",
        "  import sys; sys.path.insert(0, 'ColBERT/')\n",
        "  try:\n",
        "    from colbert import Indexer, Searcher\n",
        "  except Exception:\n",
        "    print(\"If you're running outside Colab, please make sure you install ColBERT in conda following the instructions in our README. You can also install (as above) with pip but it may install slower or less stable faiss or torch dependencies. Conda is recommended.\")\n",
        "    assert False"
      ],
      "metadata": {
        "id": "98vo3zu0aLF2"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ColBERT Imports\n",
        "import colbert\n",
        "from colbert import Indexer, Searcher\n",
        "from colbert.infra import Run, RunConfig, ColBERTConfig\n",
        "from colbert.data import Queries, Collection"
      ],
      "metadata": {
        "id": "jbR_4yFoaTPY"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import logging\n",
        "\n",
        "article_df = pd.read_csv('articles_with_text.csv')\n",
        "article_df['doc_id'] = range(len(article_df))\n",
        "\n",
        "articles_subset = article_df[['doc_id', 'article_text_raw', 'url', 'titles']]\n",
        "articles = articles_subset['article_text_raw'].tolist()\n",
        "metadata = articles_subset[['doc_id', 'url', 'titles']].set_index('doc_id').to_dict(orient='index')\n"
      ],
      "metadata": {
        "id": "g5Eq9bCRic5C"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nbits = 2   # encode each dimension with 2 bits\n",
        "doc_maxlen = 300 # truncate passages at 300 tokens\n",
        "\n",
        "index_name = f'dsan5400_project_nbits={nbits}'"
      ],
      "metadata": {
        "id": "o1dSunw-bbfo"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = 'colbert-ir/colbertv2.0'\n",
        "\n",
        "with Run().context(RunConfig(nranks=1, experiment='DSAN5400')):\n",
        "    config = ColBERTConfig(doc_maxlen=doc_maxlen, nbits=nbits, kmeans_niters=4)\n",
        "    indexer = Indexer(checkpoint=checkpoint, config=config)\n",
        "    logging.info(f\"Starting indexing process for {len(articles)} articles...\")\n",
        "    indexer.index(name=index_name, collection=articles, overwrite=True)\n",
        "    logging.info(\"Indexing complete.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305,
          "referenced_widgets": [
            "6e43e5d3137b45c98efc2fb0987d7918",
            "91d86eadf2624b95b4e362af21b0ec78",
            "65728deeee174f5798350f6b0a1b554d",
            "f1e6c21d9a7e439abc9d85298ca267f6",
            "508f7f99db2441df81f6c1ba6388fd06",
            "d103f199acef4207bb09b78538ad39b1",
            "253fa04f2f0843dd9a37d09ca36a0980",
            "5b0c0233f67a4b0497ff84390cb40d6e",
            "e51aaec57a514792bda0fc794b172051",
            "2b60d3cb563c44e1a3bd6709fbbe7d76",
            "c3b24ae7bcdd4c8694223a8682128f49"
          ]
        },
        "id": "R2iGv89OuX-d",
        "outputId": "6c257619-93de-489e-b21e-44d3711d9714"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "artifact.metadata:   0%|          | 0.00/1.63k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6e43e5d3137b45c98efc2fb0987d7918"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "[Dec 09, 23:58:12] #> Creating directory /content/experiments/DSAN5400/indexes/dsan5400_project_nbits=2 \n",
            "\n",
            "\n",
            "#> Starting...\n",
            "#> Joined...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# To create the searcher using its relative name (i.e., not a full path), set\n",
        "# experiment=value_used_for_indexing in the RunConfig.\n",
        "with Run().context(RunConfig(experiment='DSAN5400')):\n",
        "    searcher = Searcher(index=index_name, collection=articles)\n",
        "\n",
        "\n",
        "# If you want to customize the search latency--quality tradeoff, you can also supply a\n",
        "# config=ColBERTConfig(ncells=.., centroid_score_threshold=.., ndocs=..) argument.\n",
        "# The default settings with k <= 10 (1, 0.5, 256) gives the fastest search,\n",
        "# but you can gain more extensive search by setting larger values of k or\n",
        "# manually specifying more conservative ColBERTConfig settings (e.g. (4, 0.4, 4096))."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kh4iXEjT0Crx",
        "outputId": "8518cb6e-ec44-49d3-c933-4fd0db403bbd"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Dec 10, 00:03:22] #> Loading codec...\n",
            "[Dec 10, 00:03:22] Loading decompress_residuals_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/ColBERT/colbert/utils/amp.py:12: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.scaler = torch.cuda.amp.GradScaler()\n",
            "/content/ColBERT/colbert/indexing/codecs/residual.py:141: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  centroids = torch.load(centroids_path, map_location='cpu')\n",
            "/content/ColBERT/colbert/indexing/codecs/residual.py:142: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  avg_residual = torch.load(avgresidual_path, map_location='cpu')\n",
            "/content/ColBERT/colbert/indexing/codecs/residual.py:143: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  bucket_cutoffs, bucket_weights = torch.load(buckets_path, map_location='cpu')\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/cpp_extension.py:1964: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n",
            "If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Dec 10, 00:03:22] Loading packbits_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/cpp_extension.py:1964: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n",
            "If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Dec 10, 00:03:22] #> Loading IVF...\n",
            "[Dec 10, 00:03:22] #> Loading doclens...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/ColBERT/colbert/search/index_loader.py:33: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  ivf, ivf_lengths = torch.load(os.path.join(self.index_path, \"ivf.pid.pt\"), map_location='cpu')\n",
            "100%|██████████| 1/1 [00:00<00:00, 1192.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Dec 10, 00:03:22] #> Loading codes and residuals...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]/content/ColBERT/colbert/indexing/codecs/residual_embeddings.py:86: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(codes_path, map_location='cpu')\n",
            "/content/ColBERT/colbert/indexing/codecs/residual_embeddings.py:93: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(residuals_path, map_location='cpu')\n",
            "100%|██████████| 1/1 [00:00<00:00, 21.69it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the index from URL\n",
        "def get_article_index_by_url(url, metadata):\n",
        "    for idx, metadata_info in metadata.items():\n",
        "        if metadata_info['url'] == url:\n",
        "            return idx\n",
        "    return None\n",
        "\n",
        "# Prompt for URL\n",
        "user_url = input(\"Please enter the URL of the article: \")\n",
        "\n",
        "# Find the index from URL\n",
        "article_index = get_article_index_by_url(user_url, metadata)\n",
        "\n",
        "# Function with error handling\n",
        "if article_index is not None:\n",
        "    query = articles[article_index]\n",
        "    query_metadata = metadata.get(article_index, None)\n",
        "    print(\"Showing top 5 most similar articles to: \" + query_metadata['titles'])\n",
        "    print(f\"\\n\")\n",
        "\n",
        "    # Perform the search to find the top-k passages\n",
        "    results = searcher.search(query, k=6)\n",
        "\n",
        "    # Print out the top-5 retrieved passages excluding the first one (result 1)\n",
        "    for i, (passage_id, passage_rank, passage_score) in enumerate(zip(*results)):\n",
        "        if i == 0:\n",
        "            continue\n",
        "\n",
        "        if passage_id < len(searcher.collection):\n",
        "            metadata_info = metadata.get(passage_id, None)\n",
        "\n",
        "            if metadata_info:\n",
        "                url = metadata_info['url']\n",
        "                title = metadata_info['titles']\n",
        "            else:\n",
        "                url = \"URL not found\"\n",
        "                title = \"Title not found\"\n",
        "\n",
        "            print(f\"Rank: {passage_rank - 1}\")\n",
        "            print(f\"Title: {title}\")\n",
        "            print(f\"URL: {url}\")\n",
        "            print(f\"Passage ID: {passage_id}\")\n",
        "            print(f\"\\n\")\n",
        "        else:\n",
        "            print(f\"Warning: Passage ID {passage_id} is out of range for the collection.\")\n",
        "else:\n",
        "    print(\"No article found for the given URL.\")\n"
      ],
      "metadata": {
        "id": "Hzd-QKwIe9-P"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}