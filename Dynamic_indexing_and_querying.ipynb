{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jaredzrks0/DSAN5400_final_project/blob/main/DSAN_5400_Final_News_Recommender_Training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install ujson"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "on3-8w_QQof8",
        "outputId": "cfc28c3d-2ecb-4303-8235-71056fe5942e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ujson\n",
            "  Downloading ujson-5.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.3 kB)\n",
            "Downloading ujson-5.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (53 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/53.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ujson\n",
            "Successfully installed ujson-5.10.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import pandas as pd\n",
        "import re\n",
        "import logging\n",
        "import time\n",
        "import json"
      ],
      "metadata": {
        "id": "4gbPC0EDCkJn"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install ColBERT and dependencies\n",
        "try:\n",
        "    import google.colab\n",
        "    !git -C ColBERT/ pull || git clone https://github.com/stanford-futuredata/ColBERT.git > /dev/null 2>&1\n",
        "    !pip install -q fsspec==2024.9.0 faiss-gpu torch torchvision torchaudio > /dev/null 2>&1\n",
        "    sys.path.insert(0, 'ColBERT/')\n",
        "except Exception:\n",
        "    raise RuntimeError(\"Failed to install ColBERT. Ensure you are in Google Colab or set it up manually.\")\n",
        "\n",
        "# Verify GPU availability\n",
        "import torch\n",
        "if not torch.cuda.is_available():\n",
        "    print(\"Warning: GPU is not available. Performance may be slower.\")\n",
        "else:\n",
        "    print(f\"Using GPU: {torch.cuda.get_device_name(0)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_u2-m49iPCW3",
        "outputId": "8c76c976-0140-45b1-af74-7d180b76abb8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Already up to date.\n",
            "Using GPU: Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up logging\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(\"ColBERT\")\n",
        "\n",
        "# Download ColBERT Checkpoint\n",
        "logger.info(\"Downloading ColBERT checkpoint...\")\n",
        "checkpoint_url = \"https://downloads.cs.stanford.edu/nlp/data/colbert/colbertv2/colbertv2.0.tar.gz\"\n",
        "!wget -O colbertv2.0.tar.gz $checkpoint_url\n",
        "!mkdir -p checkpoints  # Create the 'checkpoints' directory if it doesn't exist\n",
        "!tar -xvzf colbertv2.0.tar.gz -C checkpoints\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Klhgw12PGM2",
        "outputId": "b0f7c767-11e0-4f69-fccb-90448c1a1d8e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-12-07 00:37:25--  https://downloads.cs.stanford.edu/nlp/data/colbert/colbertv2/colbertv2.0.tar.gz\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 405924985 (387M) [application/octet-stream]\n",
            "Saving to: ‘colbertv2.0.tar.gz’\n",
            "\n",
            "colbertv2.0.tar.gz  100%[===================>] 387.12M  5.05MB/s    in 75s     \n",
            "\n",
            "2024-12-07 00:38:40 (5.18 MB/s) - ‘colbertv2.0.tar.gz’ saved [405924985/405924985]\n",
            "\n",
            "colbertv2.0/\n",
            "colbertv2.0/artifact.metadata\n",
            "colbertv2.0/vocab.txt\n",
            "colbertv2.0/tokenizer.json\n",
            "colbertv2.0/special_tokens_map.json\n",
            "colbertv2.0/tokenizer_config.json\n",
            "colbertv2.0/config.json\n",
            "colbertv2.0/pytorch_model.bin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ColBERT Imports\n",
        "from colbert import Indexer, Searcher\n",
        "from colbert.infra import Run, RunConfig, ColBERTConfig\n",
        "from colbert.data import Queries, Collection\n",
        "\n",
        "# Load and Clean Data\n",
        "logger.info(\"Loading and cleaning data...\")\n",
        "tsv_file = \"collection.tsv\"\n",
        "\n",
        "df = pd.read_csv(tsv_file, sep='\\t', header=None)\n",
        "texts = df[0]\n",
        "articles = [text.split('\\t')[1] for text in texts if '\\t' in text]\n",
        "\n",
        "logger.info(f\"Loaded {len(articles)} articles.\")"
      ],
      "metadata": {
        "id": "uqIREx3hPLoc"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess Query Function\n",
        "def preprocess_query(query):\n",
        "    return re.sub(r'[^\\w\\s]', '', query.lower())\n"
      ],
      "metadata": {
        "id": "fpyOJ4PWPQD0"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Indexing Articles\n",
        "logger.info(\"Starting indexing...\")\n",
        "nbits = 1  # encode each dimension with 2 bits\n",
        "doc_maxlen = 300  # truncate passages at 300 tokens\n",
        "index_name = f'dsan5400_project_nbits={nbits}'\n",
        "checkpoint = 'checkpoints/colbertv2.0'\n",
        "\n",
        "# Index articles\n",
        "with Run().context(RunConfig(nranks=1, experiment='DSAN5400')):  # nranks specifies the number of GPUs to use\n",
        "    config = ColBERTConfig(doc_maxlen=doc_maxlen, nbits=nbits, kmeans_niters=4)\n",
        "    indexer = Indexer(checkpoint=checkpoint, config=config)\n",
        "    indexer.index(name=index_name, collection=articles[:500], overwrite=True)\n",
        "\n",
        "logger.info(\"Indexing complete.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "msjvl0G_PXn5",
        "outputId": "e68aaea8-295f-4ad7-fdea-db499265d654"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "[Dec 07, 00:43:05] #> Creating directory /content/experiments/DSAN5400/indexes/dsan5400_project_nbits=1 \n",
            "\n",
            "\n",
            "#> Starting...\n",
            "#> Joined...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Search Articles Dynamically\n",
        "logger.info(\"Setting up searcher...\")\n",
        "with Run().context(RunConfig(experiment='DSAN5400')):\n",
        "    searcher = Searcher(index=index_name, collection=articles[:500])\n",
        "\n",
        "print(\"\\nEnter your query below (or type 'exit' to quit):\")\n",
        "while True:\n",
        "    # get user query\n",
        "    user_query = input(\"\\nQuery: \").strip()\n",
        "    if user_query.lower() == 'exit':\n",
        "        print(\"Exiting search...\")\n",
        "        break\n",
        "\n",
        "    # Preprocess Query\n",
        "    query = preprocess_query(user_query)\n",
        "\n",
        "    # Perform search\n",
        "    start_time = time.time()  # Start timer\n",
        "    results = searcher.search(query, k=3)  # Retrieve top-3 results\n",
        "    print(f\"\\nQuery executed in {time.time() - start_time:.2f} seconds\")\n",
        "\n",
        "    # Display Results\n",
        "    print(\"\\nTop-3 Results:\\n\")\n",
        "    for passage_id, passage_rank, passage_score in zip(*results):\n",
        "        print(f\"Passage ID: {passage_id}\")\n",
        "        print(f\"Rank: {passage_rank}\")\n",
        "        print(f\"Score: {passage_score:.2f}\")\n",
        "        print(f\"Content: {searcher.collection[passage_id][:200]}...\")\n",
        "        print(\"\\n---\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XzLlNnxdoS0I",
        "outputId": "fddfafe8-7a05-4efc-878d-15565085c6b1"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Dec 07, 01:00:28] #> Loading codec...\n",
            "[Dec 07, 01:00:28] #> Loading IVF...\n",
            "[Dec 07, 01:00:28] #> Loading doclens...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 4240.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Dec 07, 01:00:29] #> Loading codes and residuals...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "100%|██████████| 1/1 [00:00<00:00, 464.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Enter your query below (or type 'exit' to quit):\n",
            "\n",
            "Query: election fraud\n",
            "\n",
            "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
            "#> Input: election fraud, \t\t True, \t\t None\n",
            "#> Output IDs: torch.Size([32]), tensor([ 101,    1, 2602, 9861,  102,  103,  103,  103,  103,  103,  103,  103,\n",
            "         103,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,\n",
            "         103,  103,  103,  103,  103,  103,  103,  103], device='cuda:0')\n",
            "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "\n",
            "\n",
            "Query executed in 0.03 seconds\n",
            "\n",
            "Top-3 Results:\n",
            "\n",
            "Passage ID: 94\n",
            "Rank: 1\n",
            "Score: 22.11\n",
            " When Donald Trump lost his re-election bid in 2020, many Republicans — Trump inclu...\n",
            "\n",
            "---\n",
            "\n",
            "Passage ID: 56\n",
            "Rank: 2\n",
            "Score: 21.27\n",
            " On election night 2020, then-President Donald Trump prematurely...\n",
            "\n",
            "---\n",
            "\n",
            "Passage ID: 110\n",
            "Rank: 3\n",
            "Score: 21.20\n",
            " Just hours after the polls closed in the 2020 United States presidential elect...\n",
            "\n",
            "---\n",
            "\n",
            "\n",
            "Query: donald trump\n",
            "\n",
            "Query executed in 0.03 seconds\n",
            "\n",
            "Top-3 Results:\n",
            "\n",
            "Passage ID: 184\n",
            "Rank: 1\n",
            "Score: 23.12\n",
            " The vote was called in favour of the Republic...\n",
            "\n",
            "---\n",
            "\n",
            "Passage ID: 14\n",
            "Rank: 2\n",
            "Score: 23.08\n",
            "Content: Donald Trump has declared victory in the 2024 US presidential election, after several battleground states were called in his favour. He spoke to supporters in Florida....\n",
            "\n",
            "---\n",
            "\n",
            "Passage ID: 165\n",
            "Rank: 3\n",
            "Score: 22.89\n",
            " The v...\n",
            "\n",
            "---\n",
            "\n",
            "\n",
            "Query: kamala harris\n",
            "\n",
            "Query executed in 0.03 seconds\n",
            "\n",
            "Top-3 Results:\n",
            "\n",
            "Passage ID: 202\n",
            "Rank: 1\n",
            "Score: 25.41\n",
            " Kamala Harris is the first African-American, South Asian woman running for president of the United States under a major party ticket. With over 34 millio...\n",
            "\n",
            "---\n",
            "\n",
            "Passage ID: 104\n",
            "Rank: 2\n",
            "Score: 24.61\n",
            "Content: “Let us fight for this beautiful country we love.” Democratic presidential candidate Kamala Harris made what was billed as her final pitch to voters one week before the US election. She delivered her ...\n",
            "\n",
            "---\n",
            "\n",
            "Passage ID: 148\n",
            "Rank: 3\n",
            "Score: 24.22\n",
            "Content: Democratic presidential candidate Kamala Harris rallied her supporters in the must-win swing state of Pennsylvania on the eve of the US presidential election....\n",
            "\n",
            "---\n",
            "\n",
            "\n",
            "Query: exit\n",
            "Exiting search...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save Results\n",
        "output_file = \"search_results.json\"\n",
        "import json\n",
        "\n",
        "with open(output_file, \"w\") as f:\n",
        "    json.dump({\"query\": query, \"results\": results}, f, indent=4)\n",
        "logger.info(f\"Results saved to {output_file}.\")\n"
      ],
      "metadata": {
        "id": "TpwvrUnpPeeH"
      },
      "execution_count": 15,
      "outputs": []
    }
  ]
}